\documentclass[a4paper]{LTJournalArticle}

\addbibresource{sample.bib} % BibLaTeX bibliography file

\runninghead{Shortened Running Article Title} % A shortened article title to appear in the running head, leave this command empty for no running head

\footertext{\textit{Journal of Biological Sampling} (2024) 12:533-684} % Text to appear in the footer, leave this command empty for no footer text

\setcounter{page}{1} % The page number of the first page, set this to a higher number if the article is to be part of an issue or larger work

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{Knowledge Graph Attention Network Review}
\author{Babiński Michał \\
        Dymanowski Krzysztof \\
        Wesołowski Jędrzej \\
        Gdańsk University of Technology \\
        \texttt{TODO}}
% Authors are listed in a comma-separated list with superscript numbers indicating affiliations
% \thanks{} is used for any text that should be placed in a footnote on the first page, such as the corresponding author's email, journal acceptance dates, a copyright/license notice, keywords, etc
% \author{%
% 	John Smith\textsuperscript{1,2}, Robert Smith\textsuperscript{3} and Jane Smith\textsuperscript{1}\thanks{Corresponding author: \href{mailto:jane@smith.com}{jane@smith.com}\\ \textbf{Received:} October 20, 2023, \textbf{Published:} December 14, 2023}
% }

% Affiliations are output in the \date{} command
\date{\footnotesize\textsuperscript{\textbf{1}}Gdansk University of Technology\\ \textsuperscript{\textbf{2}}Electronics and Information Science Department}

% Full-width abstract
\renewcommand{\maketitlehookd}{%
	\begin{abstract}
		\noindent Knowledge Graph Attention Network (KGAT) to system rekomendacyjny który łączy interakcje user-item (użytkownik-przedmiot) z 
		bogatymi informacjami kontekstowymi z grafów wiedzy (KG). W przeciwieństwie do tradycyjnych metod, KGAT nie traktuje
		 interakcji jako odizolowanych zdarzeń. Zamiast tego wychwytuje zależności wyższego rzędu między przedmiotami a ich atrybutami w połączonej strukturze 
		 grafu wiedzy i grafu użytkownik-przedmiot. Dzięki zastosowaniu propagacji osadzeń i mechanizmów uwagi, KGAT identyfikuje istotne powiązania, oferując
		  bardziej precyzyjne, zróżnicowane i wytłumaczalne rekomendacje.

		W tym raporcie omawiamy, jak zmodernizować framework KGAT, wykorzystując najnowsze technologie w dziedzinie uczenia 
		maszynowego opierającego się na grafach i umożliwiając uczenie modelu na maszynach GPU, co powinno wielokrotnie przyspieszyć uczenie. Dodatkowo testujemy jego 
		działanie na nowym zestawie danych, aby sprawdzić, jak dobrze dostosowuje się 
		i poprawia w różnych scenariuszach. Te eksperymenty mają za zadanie dać głębszy wgląd w to, jak te ulepszenia i różnice w danych wpływają na dokładność rekomendacji
		 oraz zachowanie ich interpretowalności.\end{abstract}
}

%----------------------------------------------------------------------------------------

\begin{document}
	
	\maketitle % Output the title section
	
	%----------------------------------------------------------------------------------------
	%	ARTICLE CONTENTS
	%----------------------------------------------------------------------------------------

	\section{Wyniki eksperymentów}
	W ramach projektu przeprocesowano zbiór danych amazon-kindle (https://www.kaggle.com/datasets/asaniczka/amazon-kindle-books-dataset-2023-130k-books) do formatu przyjmowanego przez algorytm, oraz powtórzono eksperymenty zmieniając nastawienia hiperparametrów. Ze względu na olbrzymie wymagania obliczeniowe, trening modeli przeprowadzany był przez 50 epok, zamiast domyślnego tysiąca epok które zaproponowali autorzy. Ponadto dokonano ewaluacji na przygotowanym zbiorze.
	
	
	Proces tworzenia zbioru danych:
	\begin{enumerate}
		\item Zbiór danych nie zawierał interakcji użytkownik-przedmiot, zatem trzeba było przygotować skrypt który tworzył plik .txt w formacie przyjmowanym przez implementację
		
		\item Najpierw oczyszczono zbiór tak, aby zawierał użytkowników którzy wystawili co najmniej 5 ocen.
		
		\item Na podstawie tego utworzono zbiór interakcji użytkownik - przedmiot  
		
		\begin{verbatim}
			# user_id item_id1 item_id2 item_id3 ...
			0 10 20 30
			1 15 25
			2 10 25 35
		\end{verbatim}

	
		\item Ostatnim krokiem było przygotowanie grafu wiedzy, który zawierał trójki relacji w następujący sposób  

	
		\item W tym momencie posiadamy główne pliki train.txt, test.txt oraz kg\_final.txt które są akceptowane przez algorytm.
		
		\begin{verbatim}
			# (Książka 0, Napisana przez, Autor 100)
			0 0 100   
			# (Książka 0, Sprzedana przez, Amazon.com Services LLC)
			0 1 200   
			# (Książka 0, Należy do kategorii, Rodzicielstwo i relacje)
			0 2 300   
			# (Książka 0, Opublikowana w, 2015)
			0 3 2015  
		\end{verbatim}
	
	\end{enumerate}

	Tabele wynikowe:
	
	Rozmiar embeddingów 32, learning rate 1e-4, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Amazon-book}
		\label{tab:metrics_transposed}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0043  & 0.0047  & 0.0053  & 0.0061  & 0.0065  \\
			Recall@20     & 0.0386  & 0.0414  & 0.0466  & 0.0549  & 0.0586  \\
			NDCG@20       & 0.0184  & 0.0190  & 0.0222  & 0.0261  & 0.0280  \\
			Precision@40  & 0.0036  & 0.0041  & 0.0045  & 0.0051  & 0.0054  \\
			Recall@40     & 0.0629  & 0.0711  & 0.0792  & 0.0906  & 0.0954  \\
			NDCG@40       & 0.0245  & 0.0265  & 0.0304  & 0.0351  & 0.0373  \\
			Precision@60  & 0.0032  & 0.0037  & 0.0040  & 0.0046  & 0.0048  \\
			Recall@60     & 0.0820  & 0.0937  & 0.1034  & 0.1190  & 0.1257  \\
			NDCG@60       & 0.0287  & 0.0316  & 0.0358  & 0.0414  & 0.0440  \\
			Precision@80  & 0.0029  & 0.0034  & 0.0037  & 0.0042  & 0.0044  \\
			Recall@80     & 0.1003  & 0.1144  & 0.1267  & 0.1439  & 0.1512  \\
			NDCG@80       & 0.0325  & 0.0358  & 0.0406  & 0.0465  & 0.0492  \\
			Precision@100 & 0.0027  & 0.0032  & 0.0035  & 0.0039  & 0.0041  \\
			Recall@100    & 0.1170  & 0.1342  & 0.1477  & 0.1652  & 0.1741  \\
			NDCG@100      & 0.0357  & 0.0396  & 0.0447  & 0.0507  & 0.0537  \\
			\bottomrule
		\end{tabular}
	\end{table}
	Rozmiar embeddingów 32, learning rate 1e-5, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Yelp2018}
		\label{tab:metrics_transposed}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0062  & 0.0087  & 0.0102  & 0.0115  & 0.0125  \\
			Recall@20     & 0.0122  & 0.0183  & 0.0217  & 0.0251  & 0.0271  \\
			NDCG@20       & 0.0105  & 0.0155  & 0.0185  & 0.0212  & 0.0231  \\
			Precision@40  & 0.0055  & 0.0077  & 0.0089  & 0.0099  & 0.0107  \\
			Recall@40     & 0.0200  & 0.0298  & 0.0353  & 0.0398  & 0.0429  \\
			NDCG@40       & 0.0131  & 0.0193  & 0.0229  & 0.0260  & 0.0282  \\
			Precision@60  & 0.0052  & 0.0070  & 0.0081  & 0.0090  & 0.0096  \\
			Recall@60     & 0.0279  & 0.0391  & 0.0457  & 0.0513  & 0.0549  \\
			NDCG@60       & 0.0156  & 0.0224  & 0.0263  & 0.0299  & 0.0322  \\
			Precision@80  & 0.0049  & 0.0066  & 0.0076  & 0.0083  & 0.0089  \\
			Recall@80     & 0.0346  & 0.0474  & 0.0553  & 0.0614  & 0.0655  \\
			NDCG@80       & 0.0177  & 0.0251  & 0.0294  & 0.0331  & 0.0356  \\
			Precision@100 & 0.0047  & 0.0062  & 0.0071  & 0.0078  & 0.0083  \\
			Recall@100    & 0.0403  & 0.0550  & 0.0638  & 0.0701  & 0.0747  \\
			NDCG@100      & 0.0195  & 0.0275  & 0.0321  & 0.0359  & 0.0385  \\
			\bottomrule
		\end{tabular}
	\end{table}
		
	Rozmiar embeddingów 32, learning rate 1e-5, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Last-FM}
		\label{tab:metrics_transposed}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0051  & 0.0067  & 0.0076  & 0.0081  & 0.0088  \\
			Recall@20     & 0.0183  & 0.0256  & 0.0296  & 0.0323  & 0.0348  \\
			NDCG@20       & 0.0114  & 0.0157  & 0.0182  & 0.0202  & 0.0217  \\
			Precision@40  & 0.0047  & 0.0061  & 0.0068  & 0.0073  & 0.0078  \\
			Recall@40     & 0.0346  & 0.0462  & 0.0528  & 0.0564  & 0.0609  \\
			NDCG@40       & 0.0166  & 0.0224  & 0.0256  & 0.0280  & 0.0301  \\
			Precision@60  & 0.0045  & 0.0057  & 0.0063  & 0.0067  & 0.0072  \\
			Recall@60     & 0.0499  & 0.0647  & 0.0730  & 0.0777  & 0.0834  \\
			NDCG@60       & 0.0210  & 0.0277  & 0.0314  & 0.0341  & 0.0365  \\
			Precision@80  & 0.0043  & 0.0054  & 0.0059  & 0.0063  & 0.0067  \\
			Recall@80     & 0.0643  & 0.0815  & 0.0909  & 0.0966  & 0.1038  \\
			NDCG@80       & 0.0248  & 0.0321  & 0.0361  & 0.0390  & 0.0419  \\
			Precision@100 & 0.0042  & 0.0052  & 0.0057  & 0.0060  & 0.0063  \\
			Recall@100    & 0.0778  & 0.0975  & 0.1078  & 0.1147  & 0.1219  \\
			NDCG@100      & 0.0282  & 0.0361  & 0.0404  & 0.0436  & 0.0464  \\
			\bottomrule
		\end{tabular}
	\end{table}
	
	Dla zbioru amazon-kindle wyniki prezentują się nastepująco:
	Rozmiar embeddingów 32, learning rate 1e-4, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Amazon-kindle}
		\label{tab:random_metrics}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0059  & 0.0049  & 0.0070  & 0.0073  & 0.0059  \\
			Recall@20     & 0.0340  & 0.0211  & 0.0184  & 0.0212  & 0.0204  \\
			NDCG@20       & 0.0210  & 0.0179  & 0.0110  & 0.0178  & 0.0224  \\
			Precision@40  & 0.0061  & 0.0048  & 0.0083  & 0.0074  & 0.0056  \\
			Recall@40     & 0.0424  & 0.0271  & 0.0274  & 0.0267  & 0.0262  \\
			NDCG@40       & 0.0237  & 0.0218  & 0.0138  & 0.0230  & 0.0271  \\
			Precision@60  & 0.0050  & 0.0041  & 0.0077  & 0.0083  & 0.0048  \\
			Recall@60     & 0.0540  & 0.0314  & 0.0307  & 0.0343  & 0.0331  \\
			NDCG@60       & 0.0290  & 0.0256  & 0.0171  & 0.0295  & 0.0302  \\
			Precision@80  & 0.0054  & 0.0040  & 0.0075  & 0.0086  & 0.0057  \\
			Recall@80     & 0.0596  & 0.0395  & 0.0345  & 0.0441  & 0.0415  \\
			NDCG@80       & 0.0375  & 0.0292  & 0.0205  & 0.0329  & 0.0344  \\
			Precision@100 & 0.0062  & 0.0040  & 0.0061  & 0.0075  & 0.0046  \\
			Recall@100    & 0.0681  & 0.0482  & 0.0443  & 0.0489  & 0.0524  \\
			NDCG@100      & 0.0426  & 0.0324  & 0.0237  & 0.0384  & 0.0428  \\
			\bottomrule
		\end{tabular}
	\end{table}

	Największy problem sprawiało utworzenie samego zbioru danych, gdyż wymagało ono od nas opracowania grafu wiedzy. Ponadto, ontologia tego grafu nie opierała się na Freebase, tak jak w przypadku pozostałych zbiorów danych, więc nie jesteśmy do końca pewni jej poprawności. Największym ograniczeniem zaś był czas treningu modelu, dla 50 epok trening jednego modelu na cPU trwał około 20 godzin na stacji roboczej (z procesorem i7 14700). Po modernizacji kodu i środowiska tak, aby korzystać z GPU, czas treningu dla 50 epok skrócił się do około 2,5 godziny. 
	\section{Introduction}
	
	\section{Opis metody}
	Sieci grafowe, takie jak Knowledge Graph Attention Network, wykorzystują graf wiedzy  do wzbogacenia systemów rekomendacyjnych. W tradycyjnych metodach, takich jak filtrowanie kolaboracyjne
	czy modele nadzorowanego uczenia, interakcje użytkownika z przedmiotami traktowane są jako niezależne zdarzenia, co ogranicza zdolność do wykorzystania informacji kontekstowych takich jak atrybuty przedmiotów, profile użytkowników itp.

KGAT wprowadza innowacyjne podejście, łącząc graf wiedzy z grafem użytkownik-przedmiot w jedną hybrydową strukturę - graf wiedzy kolaboracyjnej (CKG). 
Istotnym jego elementem jest modelowanie relacji wyższego rzędu, które uwzględniają pośrednie powiązania między użytkownikami a przedmiotami poprzez wspólne atrybuty 
(na przykład wspólny reżyser filmów któe można zarekomendować innemu użytkownikowi na bazie historii oglądania innego użytkownika). 
Aby to osiągnąć, KGAT stosuje:
Rekurencyjną propagację osadzeń(embeddings), w ramach któej osadzenia każdego węzła są aktualizowane na podstawie informacji od sąsiadów, co pozwala wydajnie uchwycić relacje wyższego rzędu, oraz 
agregację opartą na uwadze (attention), czyli attention mechanism który pozwala modelowi przypisywać różne wagi sąsiadom, uwzględniając wagę ich istotności w kontekście rekomendacji.
Zalety sieci grafowych:
\begin{itemize}
	\item Efektywne wykorzystanie informacji dodatkowych: Sieci grafowe skutecznie integrują cechy przedmiotów, profile użytkowników i inne dane kontekstowe, co poprawia wyniki rekomendacji.
\item Modelowanie relacji wyższego rzędu: KGAT potrafi uchwycić dalekie powiązania między węzłami, co jest problematyczne dla tradycyjnych metod.
\item Interpretowalność: Mechanizm uwagi pozwala interpretować, które relacje miały największy wpływ na wyniki modelu.
\item Brak potrzeby ręcznego definiowania ścieżek: W przeciwieństwie do metod opartych na ścieżkach, KGAT nie wymaga ręcznego definiowania ścieżek, co oszczędza czas i zasoby.
\end{itemize}

Wady sieci grafowych:
\begin{itemize}
	\item Wysokie wymagania obliczeniowe: Liczba węzłów i relacji rośnie eksponencjalnie wraz ze wzrostem złożoności grafu, co może być problematyczne dla większych problemów.
	\item Złożoność modelowania relacji: Relacje wyższego rzędu wnoszą różny wkład do rekomendacji, co wymaga precyzyjnego ważenia i selekcji.
	\item Brak interpretowalności w niektórych modelach: Chociaż KGAT stawia na interpretowalność, inne podejścia (np. regularizacyjne) mogą być trudniejsze do zrozumienia.
\end{itemize}
\section{Opis architektury}
\subsection{Szczegółowy opis algorytmu}
	
Algorytm KGAT składa się z trzech głównych komponentów:
\begin{itemize}
	\item Warstwa osadzania: Parametryzuje każdy węzeł jako wektor, zachowując strukturę grafu wiedzy.
	\item Warstwy propagacji osadzania z uwzględnieniem uwagi: Rekurencyjnie propagują osadzenia od sąsiadów węzła, aktualizując jego reprezentację i ucząc się wagi każdego sąsiada podczas propagacji.
	\item Warstwa predykcji: Agreguje reprezentacje użytkownika i przedmiotu ze wszystkich warstw propagacji i zwraca przewidywany wynik dopasowania.
\end{itemize}
\subsection{Parametry Algorytmu}
Wśród parametrów modelu możemy wyróżnić hiperparametry, w tym przypadku wymiar warstwy osadzeń i liczba wartsw propagacji. Dodatkowo algorytm dynamicznie wybiera rozmiary
osadzeń w zależności od węzłów, co pozwala na bardziej elastyczne modelowanie relacji oraz wagi warstwy attention (warstwy uwagi. wagi uwagi brzmiały na tyle głupio że wolę używeać angielskiego).
\subsection{Format danych wejściowych}
Danymi wejściowymi grafu są trójki relacji między węzłami, w formacie (h, r, t), gdzie h to węzeł początkowy, r to relacja między węzłami, a t to węzeł docelowy.\\
Danymi wyjściowymi są przewidywane wyniki dopasowania użytkownika do przedmiotu.

\subsection{Uniwersalność}
Algorytm może być stosowany w różnych domenach, ale wymaga odpowiedniego grafu wiedzy który trzeba przygotować przed procesem uczenia. Dodatkowo jego 
złożoność obliczeniowa sprawia, że może być problematyczny bądź nawet niemożliwy dla większych zbiorów danych.
	\section{Task 2}
	W drugim etapie projektu studenci analizują kod dołączony do wybranego
	w pierwszym etapie artykułu naukowego. W pierwszej kolejności studenci
	powinni skupić się na sposobie zaimplementowania proponowanej przez
	autorów artykułu metody, w tym na poprawność implementacji oraz ciekawe
	rozwiązania techniczne.
	W kolejnym kroku studenci powinni przeanalizować sposób
	przeprowadzenia eksperymentu. Jaki zbiór danych został użyty? W jaki sposób
	dokonano podziału danych? Z jakich metod i miar skorzystano? Czy protokół
	oceny algorytmu odpowiada problemowi, który autorzy artykułu chcieli
	rozwiązać?
	W ostatniej części etapu studenci powinni powtórzyć eksperyment opisany
	w wybranym artykule z wykorzystaniem analizowanego we wcześniejszych
	krokach kodu. Co należy zrobić, aby uruchomić kod? Czy wystarczy jedno
	uruchomienie, czy np. istnieje plik konfiguracyjny, który należy modyfikować,
	aby otrzymać wszystkie raportowane w artykule wyniki? Czy wyniki zgadzają się
	z tym, które zostały zaraportowane w artykule przez autorów? Jeżeli nie, to
	dlaczego tak jest? Jakie mogą być tego konsekwencje?

	\subsection{Prezentacja do Etapu II}
	Prezentacja z Etapu II powinna zawierać podstawowe informacje
	o autorach, tj. imiona, nazwiska i numery indeksów wszystkich członków
	zespołu projektowego oraz informacje o analizowanym artykule, tj. nazwiska
	autorów i tytuł. 
	Poniżej podano elementy merytoryczne prezentacji. (Jeżeli czegoś z poniższych
	nie można zastosować dla konkretnego tematu, to powinno zostać pominięte – 
	ewentualnie umieszczone na slajdzie, ale nie omówione podczas prezentacji.)
	\begin{enumerate}
		\item Omówienie algorytmu, czyli streszczenie etapu 1 celem zrozumienia
		dalszej części prezentacji przez kolegów (tylko i aż tyle!).
		\item Analiza kodu
		\begin{enumerate}
			\item Poprawność implementacji (błędy metody i merytoryczne, tj.
			niezgodność z opisem metody).
			\item Ciekawe rozwiązania techniczne, np. optymalizacja obliczeń itp.
		\end{enumerate}
		\item Opis użytego w eksperymencie zbioru/zbiorów danych
		\begin{enumerate}
			\item Jaki był cel zbierania zbioru?
			\item Kto jest twórcą/właścicielem zbioru?
			\item Jakie dane zawiera?
			\item Co one oznaczają?
			\item Jakie są wartości dla podstawowych charakterystyk zbioru danych?
			\begin{enumerate}
				\item Ilość ocen, użytkowników i produktów.
				\item Średnie ilości ocen na użytkownika/produkt.
				\item Gęstość macierzy ocen.
				\item Dodatkowe informacje zawarte w zbiorze charakterystyczne dla
				rozwiązywanego problemu/proponowanej metody.
			\end{enumerate}
		\end{enumerate}
		\item Analiza eksperymentu
		\begin{enumerate}
			\item Z jakich metod ewaluacji skorzystano?
			\item Z jakich miar oceny systemów rekomendacyjnych skorzystano? Dlaczego?
			\item Czy wykorzystano odpowiedni zbiór danych do rozwiązywanego
			problemu?
			\item W jaki sposób dokonano podziału danych? Czy przeprowadzano na
			nich jakieś dodatkowe transformacje?
			\item Czy protokół oceny algorytmu odpowiada problemowi, który autorzy
			artykułu chcieli rozwiązać?
		\end{enumerate}
		\item Wykonanie kodu
		\begin{enumerate}
			\item W jaki sposób uruchamia się program?
			\item Czy istnieją jakieś pliki konfiguracyjne? Jakie? Do czego służą?
			\item Jak długo trzeba czekać na wyniki? (nie wymaga się podawania
			dokładnych danych).
		\end{enumerate}
		\item Wyniki i wnioski
		\begin{enumerate}
			\item Wyniki własnego wykonania w zestawieniu z wynikami z artykułu.
			\item Czy wyniki się różnią?
			\item Jaka może być tego przyczyna?
			\item Jakie mogą być tego konsekwencje?
			\item Czy uważasz, że algorytm został poprawnie zwalidowany? Dlaczego?
			\item Czy widzisz sposób na ulepszenie/modyfikację tego eksperymentu?
		\end{enumerate}
	\end{enumerate}

	\section{Task 3}
	W trzecim etapie projektu studenci, korzystając z wiedzy zdobytej 
	w poprzednich dwóch etapach projektu, proponują własną modyfikację algorytmu 
	i/lub eksperymentu przeprowadzonego przez autorów oryginalnego artykułu i 
	planują eksperyment mający na celu weryfikację zaproponowanej modyfikacji.
	Na początku studenci powinni przemyśleć możliwe modyfikacje, które 
	zidentyfikowali w poprzednich sprawozdaniach. Można też rozszerzyć pulę 
	o nowe propozycje. Studenci powinni opisać wszystkie zidentyfikowane przez 
	siebie możliwe modyfikacje, zarówno samego algorytmu, jak i eksperymentu (nie 
	obliguje to do implementacji wszystkich rozszerzeń w kolejnym etapie).
	Podczas opisu każdej z możliwych modyfikacji algorytmu i/lub 
	eksperymentu, studenci powinni rozważyć następujące kwestie:
	\begin{itemize}
		\item Na czym polega dana modyfikacja?
		\item W jaki sposób zmieni ona sposób wykonania algorytmu/eksperymentu?
		\item W którym miejscu w kodzie będą wprowadzone zmiany?
		\item Jakie są motywacje wprowadzenia danej modyfikacji?
		\item Czy pozwoli ona ulepszyć algorytm/eksperyment? W jaki sposób?
		\item W przypadku modyfikacji eksperymentu powinno się rozważyć również pytania:
		\begin{itemize}
			\item Jaką nową wiedzę o metodzie możemy zyskać dzięki danej modyfikacji eksperymentu?
			\item Do czego w praktyce może się ta wiedza przydać?
		\end{itemize}
	\end{itemize}
	W ostatniej części etapu trzeciego studenci wybierają dwie modyfikacje i 
	planują dla nich eksperymenty. Należy również uzasadnić wybór modyfikacji do 
	implementacji.
	Plan eksperymentu powinien zawierać informacje o tym, co będzie badane 
	i w jaki sposób. Studenci powinni zidentyfikować wszystkie zmienne zależne i
	niezależne, w tym również hiperparametry wymagające wcześniejszego 
	strojenia. Każdy krok eksperymentu powinien być dokładnie zaplanowany i 
	opisany. Ważny jest również wybór i opis zbiorów danych do eksperymentu.

	\subsection{Prezentacja do Etapu III}
	Prezentacja z Etapu III powinna zawierać podstawowe informacje 
	o autorach, tj. imiona, nazwiska i numery indeksów wszystkich członków zespołu 
	projektowego oraz informacje o analizowanym artykule, tj. nazwiska autorów i 
	tytuł. 
	Poniżej podano wymagane elementy merytoryczne sprawozdania.
	Prezentacja powinna trwać 10-12 minut.
	\begin{enumerate}
		\item Możliwe modyfikacje
		\begin{itemize}
			\item Dla każdej zidentyfikowanej możliwej modyfikacji, studenci powinni rozważyć następujące elementy:
			\begin{enumerate}
				\item Istota modyfikacji
				\begin{itemize}
					\item Typ modyfikacji (algorytmu czy eksperymentu).
					\item Na czym polega dana modyfikacja?
					\item W jaki sposób zmieni ona sposób wykonania algorytmu/eksperymentu?
					\item W którym miejscu w kodzie będą wprowadzone zmiany?
				\end{itemize}
				\item Motywacje do wprowadzenia danej modyfikacji
				\begin{itemize}
					\item Jakie są motywacje wprowadzenia danej modyfikacji?
					\item Czy pozwoli ona ulepszyć algorytm/eksperyment? W jaki sposób?
					\item Opcjonalne (tylko w przypadku modyfikacji eksperymentu): Jaką nową wiedzę o metodzie możemy zyskać dzięki danej modyfikacji eksperymentu? Do czego w praktyce może się ta wiedza przydać?
				\end{itemize}
			\end{enumerate}
		\end{itemize}
		\item Plan eksperymentu
		\begin{enumerate}
			\item Wybór modyfikacji
			\begin{itemize}
				\item Która z powyższych modyfikacji została wybrana do implementacji? Dlaczego akurat ta?
			\end{itemize}
			\item Opis eksperymentu
			\begin{itemize}
				\item Dokładny opis planowanego eksperymentu.
				\item Jakie zbiory danych zostaną wykorzystane?
				\item Jakie kroki zostaną przeprowadzone?
				\item Co będziemy badać?
				\item Jakie będą zmienne zależne a jakie niezależne w projektowanym eksperymencie?
				\item Czy będą wykorzystywane miary jakości systemów rekomendacyjnych? Jeśli tak, to jakie?
				\item Czy wymagane jest wcześniejsze strojenie hiperparametrów modelu? Jeżeli tak, to których i w jaki sposób będzie wykonane?
			\end{itemize}
		\end{enumerate}
	\end{enumerate}

	\section{Task 4}
	W czwartym etapie projektu studenci, korzystając z planu eksperymentu
	zaprojektowanego w trzecim etapie, przeprowadzają eksperyment naukowy,
	analizują jego wyniki i formułują wnioski.
	W pierwszej części czwartego etapu studenci powinni wykonać dwa
	eksperymenty zgodnie z planem opisanym w sprawozdaniu do etapu trzeciego.
	Istotna jest tutaj zgodność z opisanym planem. Jeżeli wystąpią jakiekolwiek
	trudności z realizacją zaplanowanych w eksperymencie czynności, studenci
	powinni opisać te problemy wraz z rozwiązaniem, które zostało zastosowane.
	Wszelkie modyfikacje planu również powinny zostać skrupulatnie opisane.
	Po wykonaniu każdego z eksperymentów, studenci powinni zebrać
	otrzymane wyniki w wygodnej do analizy formie, np. wykres, tabela. Dobrze by
	było, gdyby zostały przedstawione w takiej formie, która umożliwia porównanie
	otrzymanych wyników z tymi z oryginalnego artykułu (w uzasadnionych
	przypadkach nie jest to konieczne). Otrzymane wyniki powinny zostać
	przeanalizowane samodzielnie, jak również porównane z tymi z oryginalnego
	artykułu (o ile to możliwe). Na podstawie planu modyfikacji i wyników oraz
	oryginalnego artykułu, studenci powinni wyciągnąć wnioski z przeprowadzonych
	badań (dla każdego eksperymentu osobno).
	W ostatniej części etapu czwartego studenci podsumowują pracę ze
	wszystkich dotychczasowych etapów i wyciągają wnioski końcowe. Kluczowe
	jest zidentyfikowanie, czy podczas przeprowadzonych eksperymentów powstała
	nowa wiedza o badanym algorytmie (i opisanie jej, jeśli tak). Możliwe jest tu
	uwzględnienie wszelkich uwag dotyczących oryginalnej metody, procedury
	ewaluacji, zaimplementowanych modyfikacjach i otrzymanych wyników.

	\subsection{Prezentacja do Etapu IV}
	Prezentacja z Etapu IV powinna zawierać podstawowe informacje
	o autorach, tj. imiona, nazwiska i numery indeksów wszystkich członków
	zespołu projektowego oraz informacje o analizowanym artykule, tj. nazwiska
	autorów i tytuł. 
	Poniżej podano ramowe elementy merytoryczne sprawozdania.
	\begin{enumerate}
		\item Analizowany algorytm
		\begin{itemize}
			\item Krótkie przypomnienie, co robi analizowany algorytm.
		\end{itemize}
		\item Eksperymenty
		\begin{enumerate}
			\item Przebieg eksperymentu
			\begin{itemize}
				\item Dokładny opis przeprowadzonego eksperymentu.
				\item Czy udało się przeprowadzić modyfikację zgodnie z założonym planem? Jeśli nie, to co się zmieniło?
				\item Czy wystąpiły jakieś niespodziewane problemy? Jeśli tak, to jakie?
			\end{itemize}
			\item Wyniki
			\begin{itemize}
				\item Dokładny opis otrzymanych wyników z eksperymentu wraz z tabelami i/lub wykresami.
			\end{itemize}
			\item Porównanie wyników i wnioski
			\begin{itemize}
				\item Czy wyniki różnią się od wyników otrzymanych przez autorów oryginalnego artykułu? Jeśli tak, to czy są lepsze czy gorsze? Jak myślisz, dlaczego tak jest?
				\item Jeśli modyfikacją było nowe zastosowanie metody, to czy po przeprowadzonym eksperymencie możemy uznać, że metoda sprawdzi się w tym zastosowaniu? Dlaczego? Itd.
			\end{itemize}
		\end{enumerate}
		\item Wnioski końcowe
		\begin{itemize}
			\item Co możesz powiedzieć o oryginalnym algorytmie i własnych modyfikacjach po przeprowadzeniu eksperymentów?
			\item Czy możesz wysnuć jakieś wnioski z wszystkich eksperymentów (z artykułu i własnych)?
			\item Czy powstała nowa wiedza podczas realizacji projektu? Jeśli tak, to jaka? Itp.
		\end{itemize}
	\end{enumerate}

	\section{Task 5}
	\subsection{Przebieg Etapu V}
	W piątym etapie projektu studenci przygotowują artykuł naukowy zgodnie
	z załączonym szablonem.
	Artykuł powinien zawierać wszystkie kluczowe informacje dotyczące
	wszystkich wcześniejszych etapów projektu, ze szczególnym naciskiem na etap
	czwarty (własny eksperyment i wnioski).

	\subsection{Sprawozdanie do Etapu V}
	Sprawozdanie z Etapu V będzie stanowił artykuł naukowy, który powinien
	zawierać podstawowe informacje o autorach, tj. imiona i nazwiska wszystkich
	członków zespołu projektowego oraz informacje o analizowanym artykule, tj.
	nazwiska autorów i tytuł. Ponadto, artykuł powinien zawierać następujące
	elementy:
	\begin{enumerate}
		\item Wprowadzenie do problematyki.
		\item Przegląd stanu wiedzy/istniejących modyfikacji algorytmu
		\item Analizowany algorytm
		\item Przeprowadzone eksperymenty wraz z wynikami
		\item Wnioski końcowe
	\end{enumerate}
	Dokładny dobór treści w ramach punktów jest pozostawiony studentom
	i podlega ocenie.
	Artykuł powinien być napisany w języku angielskim z wykorzystaniem
	załączonego szablonu LaTeX. Długość artykułu powinna wynosić 10-14 stron
	(łącznie z bibliografią).

	\subsection{Forma i sposób zaliczenia Etapu V}
	Za etap można otrzymać maksymalnie 8 punktów. Do zaliczenia zadania
	wymagane jest otrzymanie minimum 4 punkty. Oceniany będzie dobór i sposób
	zaprezentowania treści. Termin wgrania artykułów upływa 21.01.2024 o godz.
	23:59.

	%----------------------------------------------------------------------------------------
	%	 REFERENCES
	%----------------------------------------------------------------------------------------
	
	\printbibliography % Output the bibliography
	
	%----------------------------------------------------------------------------------------
	
\end{document}