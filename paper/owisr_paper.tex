\documentclass[a4paper]{LTJournalArticle}

\addbibresource{sample.bib} % BibLaTeX bibliography file

\runninghead{Shortened Running Article Title} % A shortened article title to appear in the running head, leave this command empty for no running head

\footertext{\textit{Journal of Biological Sampling} (2024) 12:533-684} % Text to appear in the footer, leave this command empty for no footer text

\setcounter{page}{1} % The page number of the first page, set this to a higher number if the article is to be part of an issue or larger work

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{Knowledge Graph Attention Network Review}
\author{Babiński Michał \\
        Dymanowski Krzysztof \\
        Wesołowski Jędrzej \\
        Gdańsk University of Technology \\
        \texttt{TODO}}
% Authors are listed in a comma-separated list with superscript numbers indicating affiliations
% \thanks{} is used for any text that should be placed in a footnote on the first page, such as the corresponding author's email, journal acceptance dates, a copyright/license notice, keywords, etc
% \author{%
% 	John Smith\textsuperscript{1,2}, Robert Smith\textsuperscript{3} and Jane Smith\textsuperscript{1}\thanks{Corresponding author: \href{mailto:jane@smith.com}{jane@smith.com}\\ \textbf{Received:} October 20, 2023, \textbf{Published:} December 14, 2023}
% }

% Affiliations are output in the \date{} command
\date{\footnotesize\textsuperscript{\textbf{1}}Gdansk University of Technology\\ \textsuperscript{\textbf{2}}Electronics and Information Science Department}

% Full-width abstract
\renewcommand{\maketitlehookd}{%
	\begin{abstract}
		\noindent Knowledge Graph Attention Network (KGAT) to system rekomendacyjny który łączy interakcje user-item (użytkownik-przedmiot) z 
		bogatymi informacjami kontekstowymi z grafów wiedzy (KG). W przeciwieństwie do tradycyjnych metod, KGAT nie traktuje
		 interakcji jako odizolowanych zdarzeń. Zamiast tego wychwytuje zależności wyższego rzędu między przedmiotami a ich atrybutami w połączonej strukturze 
		 grafu wiedzy i grafu użytkownik-przedmiot. Dzięki zastosowaniu propagacji osadzeń i mechanizmów uwagi, KGAT identyfikuje istotne powiązania, oferując
		  bardziej precyzyjne, zróżnicowane i wytłumaczalne rekomendacje.

		W tym raporcie omawiamy, jak zmodernizować framework KGAT, wykorzystując najnowsze technologie w dziedzinie uczenia 
		maszynowego opierającego się na grafach i umożliwiając uczenie modelu na maszynach GPU, co powinno wielokrotnie przyspieszyć uczenie. Dodatkowo testujemy jego 
		działanie na nowym zestawie danych, aby sprawdzić, jak dobrze dostosowuje się 
		i poprawia w różnych scenariuszach. Te eksperymenty mają za zadanie dać głębszy wgląd w to, jak te ulepszenia i różnice w danych wpływają na dokładność rekomendacji
		 oraz zachowanie ich interpretowalności.\end{abstract}
}

%----------------------------------------------------------------------------------------

\begin{document}
	
	\maketitle % Output the title section
	
	%----------------------------------------------------------------------------------------
	%	ARTICLE CONTENTS
	%----------------------------------------------------------------------------------------

	\section{Wyniki eksperymentów}
	W ramach projektu przeprocesowano zbiór danych amazon-kindle (https://www.kaggle.com/datasets/asaniczka/amazon-kindle-books-dataset-2023-130k-books) do formatu przyjmowanego przez algorytm, oraz powtórzono eksperymenty zmieniając nastawienia hiperparametrów. Ze względu na olbrzymie wymagania obliczeniowe, trening modeli przeprowadzany był przez 50 epok, zamiast domyślnego tysiąca epok które zaproponowali autorzy. Ponadto dokonano ewaluacji na przygotowanym zbiorze.
	
	
	Proces tworzenia zbioru danych:
	\begin{enumerate}
		\item Zbiór danych nie zawierał interakcji użytkownik-przedmiot, zatem trzeba było przygotować skrypt który tworzył plik .txt w formacie przyjmowanym przez implementację
		
		\item Najpierw oczyszczono zbiór tak, aby zawierał użytkowników którzy wystawili co najmniej 5 ocen.
		
		\item Na podstawie tego utworzono zbiór interakcji użytkownik - przedmiot  
		
		\begin{verbatim}
			# user_id item_id1 item_id2 item_id3 ...
			0 10 20 30
			1 15 25
			2 10 25 35
		\end{verbatim}

	
		\item Ostatnim krokiem było przygotowanie grafu wiedzy, który zawierał trójki relacji w następujący sposób  

	
		\item W tym momencie posiadamy główne pliki train.txt, test.txt oraz kg\_final.txt które są akceptowane przez algorytm.
		
		\begin{verbatim}
			# (Książka 0, Napisana przez, Autor 100)
			0 0 100   
			# (Książka 0, Sprzedana przez, Amazon.com Services LLC)
			0 1 200   
			# (Książka 0, Należy do kategorii, Rodzicielstwo i relacje)
			0 2 300   
			# (Książka 0, Opublikowana w, 2015)
			0 3 2015  
		\end{verbatim}
	
	\end{enumerate}

	Tabele wynikowe:
	
	Rozmiar embeddingów 32, learning rate 1e-4, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Amazon-book}
		\label{tab:metrics_transposed}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0043  & 0.0047  & 0.0053  & 0.0061  & 0.0065  \\
			Recall@20     & 0.0386  & 0.0414  & 0.0466  & 0.0549  & 0.0586  \\
			NDCG@20       & 0.0184  & 0.0190  & 0.0222  & 0.0261  & 0.0280  \\
			Precision@40  & 0.0036  & 0.0041  & 0.0045  & 0.0051  & 0.0054  \\
			Recall@40     & 0.0629  & 0.0711  & 0.0792  & 0.0906  & 0.0954  \\
			NDCG@40       & 0.0245  & 0.0265  & 0.0304  & 0.0351  & 0.0373  \\
			Precision@60  & 0.0032  & 0.0037  & 0.0040  & 0.0046  & 0.0048  \\
			Recall@60     & 0.0820  & 0.0937  & 0.1034  & 0.1190  & 0.1257  \\
			NDCG@60       & 0.0287  & 0.0316  & 0.0358  & 0.0414  & 0.0440  \\
			Precision@80  & 0.0029  & 0.0034  & 0.0037  & 0.0042  & 0.0044  \\
			Recall@80     & 0.1003  & 0.1144  & 0.1267  & 0.1439  & 0.1512  \\
			NDCG@80       & 0.0325  & 0.0358  & 0.0406  & 0.0465  & 0.0492  \\
			Precision@100 & 0.0027  & 0.0032  & 0.0035  & 0.0039  & 0.0041  \\
			Recall@100    & 0.1170  & 0.1342  & 0.1477  & 0.1652  & 0.1741  \\
			NDCG@100      & 0.0357  & 0.0396  & 0.0447  & 0.0507  & 0.0537  \\
			\bottomrule
		\end{tabular}
	\end{table}
	Rozmiar embeddingów 32, learning rate 1e-5, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Yelp2018}
		\label{tab:metrics_transposed}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0062  & 0.0087  & 0.0102  & 0.0115  & 0.0125  \\
			Recall@20     & 0.0122  & 0.0183  & 0.0217  & 0.0251  & 0.0271  \\
			NDCG@20       & 0.0105  & 0.0155  & 0.0185  & 0.0212  & 0.0231  \\
			Precision@40  & 0.0055  & 0.0077  & 0.0089  & 0.0099  & 0.0107  \\
			Recall@40     & 0.0200  & 0.0298  & 0.0353  & 0.0398  & 0.0429  \\
			NDCG@40       & 0.0131  & 0.0193  & 0.0229  & 0.0260  & 0.0282  \\
			Precision@60  & 0.0052  & 0.0070  & 0.0081  & 0.0090  & 0.0096  \\
			Recall@60     & 0.0279  & 0.0391  & 0.0457  & 0.0513  & 0.0549  \\
			NDCG@60       & 0.0156  & 0.0224  & 0.0263  & 0.0299  & 0.0322  \\
			Precision@80  & 0.0049  & 0.0066  & 0.0076  & 0.0083  & 0.0089  \\
			Recall@80     & 0.0346  & 0.0474  & 0.0553  & 0.0614  & 0.0655  \\
			NDCG@80       & 0.0177  & 0.0251  & 0.0294  & 0.0331  & 0.0356  \\
			Precision@100 & 0.0047  & 0.0062  & 0.0071  & 0.0078  & 0.0083  \\
			Recall@100    & 0.0403  & 0.0550  & 0.0638  & 0.0701  & 0.0747  \\
			NDCG@100      & 0.0195  & 0.0275  & 0.0321  & 0.0359  & 0.0385  \\
			\bottomrule
		\end{tabular}
	\end{table}
		
	Rozmiar embeddingów 32, learning rate 1e-5, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Last-FM}
		\label{tab:metrics_transposed}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0051  & 0.0067  & 0.0076  & 0.0081  & 0.0088  \\
			Recall@20     & 0.0183  & 0.0256  & 0.0296  & 0.0323  & 0.0348  \\
			NDCG@20       & 0.0114  & 0.0157  & 0.0182  & 0.0202  & 0.0217  \\
			Precision@40  & 0.0047  & 0.0061  & 0.0068  & 0.0073  & 0.0078  \\
			Recall@40     & 0.0346  & 0.0462  & 0.0528  & 0.0564  & 0.0609  \\
			NDCG@40       & 0.0166  & 0.0224  & 0.0256  & 0.0280  & 0.0301  \\
			Precision@60  & 0.0045  & 0.0057  & 0.0063  & 0.0067  & 0.0072  \\
			Recall@60     & 0.0499  & 0.0647  & 0.0730  & 0.0777  & 0.0834  \\
			NDCG@60       & 0.0210  & 0.0277  & 0.0314  & 0.0341  & 0.0365  \\
			Precision@80  & 0.0043  & 0.0054  & 0.0059  & 0.0063  & 0.0067  \\
			Recall@80     & 0.0643  & 0.0815  & 0.0909  & 0.0966  & 0.1038  \\
			NDCG@80       & 0.0248  & 0.0321  & 0.0361  & 0.0390  & 0.0419  \\
			Precision@100 & 0.0042  & 0.0052  & 0.0057  & 0.0060  & 0.0063  \\
			Recall@100    & 0.0778  & 0.0975  & 0.1078  & 0.1147  & 0.1219  \\
			NDCG@100      & 0.0282  & 0.0361  & 0.0404  & 0.0436  & 0.0464  \\
			\bottomrule
		\end{tabular}
	\end{table}
	
	Dla zbioru amazon-kindle wyniki prezentują się nastepująco:
	Rozmiar embeddingów 32, learning rate 1e-4, bez pre-treningu:
	\begin{table}[h]
		\centering
		\caption{Amazon-kindle}
		\label{tab:random_metrics}
		\scriptsize % Adjust font size if necessary
		\begin{tabular}{ccccccc}
			\toprule
			Metric & 10 Epochs & 20 Epochs & 30 Epochs & 40 Epochs & 50 Epochs \\
			\midrule
			Precision@20  & 0.0059  & 0.0049  & 0.0070  & 0.0073  & 0.0059  \\
			Recall@20     & 0.0340  & 0.0211  & 0.0184  & 0.0212  & 0.0204  \\
			NDCG@20       & 0.0210  & 0.0179  & 0.0110  & 0.0178  & 0.0224  \\
			Precision@40  & 0.0061  & 0.0048  & 0.0083  & 0.0074  & 0.0056  \\
			Recall@40     & 0.0424  & 0.0271  & 0.0274  & 0.0267  & 0.0262  \\
			NDCG@40       & 0.0237  & 0.0218  & 0.0138  & 0.0230  & 0.0271  \\
			Precision@60  & 0.0050  & 0.0041  & 0.0077  & 0.0083  & 0.0048  \\
			Recall@60     & 0.0540  & 0.0314  & 0.0307  & 0.0343  & 0.0331  \\
			NDCG@60       & 0.0290  & 0.0256  & 0.0171  & 0.0295  & 0.0302  \\
			Precision@80  & 0.0054  & 0.0040  & 0.0075  & 0.0086  & 0.0057  \\
			Recall@80     & 0.0596  & 0.0395  & 0.0345  & 0.0441  & 0.0415  \\
			NDCG@80       & 0.0375  & 0.0292  & 0.0205  & 0.0329  & 0.0344  \\
			Precision@100 & 0.0062  & 0.0040  & 0.0061  & 0.0075  & 0.0046  \\
			Recall@100    & 0.0681  & 0.0482  & 0.0443  & 0.0489  & 0.0524  \\
			NDCG@100      & 0.0426  & 0.0324  & 0.0237  & 0.0384  & 0.0428  \\
			\bottomrule
		\end{tabular}
	\end{table}

	Największy problem sprawiało utworzenie samego zbioru danych, gdyż wymagało ono od nas opracowania grafu wiedzy. Ponadto, ontologia tego grafu nie opierała się na Freebase, tak jak w przypadku pozostałych zbiorów danych, więc nie jesteśmy do końca pewni jej poprawności. Największym ograniczeniem zaś był czas treningu modelu, dla 50 epok trening jednego modelu na cPU trwał około 20 godzin na stacji roboczej (z procesorem i7 14700). Po modernizacji kodu i środowiska tak, aby korzystać z GPU, czas treningu dla 50 epok skrócił się do około 2,5 godziny. 
	\section{Introduction}
	
	\section{Opis metody}
	Sieci grafowe, takie jak Knowledge Graph Attention Network, wykorzystują graf wiedzy  do wzbogacenia systemów rekomendacyjnych. W tradycyjnych metodach, takich jak filtrowanie kolaboracyjne
	czy modele nadzorowanego uczenia, interakcje użytkownika z przedmiotami traktowane są jako niezależne zdarzenia, co ogranicza zdolność do wykorzystania informacji kontekstowych takich jak atrybuty przedmiotów, profile użytkowników itp.

KGAT wprowadza innowacyjne podejście, łącząc graf wiedzy z grafem użytkownik-przedmiot w jedną hybrydową strukturę - graf wiedzy kolaboracyjnej (CKG). 
Istotnym jego elementem jest modelowanie relacji wyższego rzędu, które uwzględniają pośrednie powiązania między użytkownikami a przedmiotami poprzez wspólne atrybuty 
(na przykład wspólny reżyser filmów któe można zarekomendować innemu użytkownikowi na bazie historii oglądania innego użytkownika). 
Aby to osiągnąć, KGAT stosuje:
Rekurencyjną propagację osadzeń(embeddings), w ramach któej osadzenia każdego węzła są aktualizowane na podstawie informacji od sąsiadów, co pozwala wydajnie uchwycić relacje wyższego rzędu, oraz 
agregację opartą na uwadze (attention), czyli attention mechanism który pozwala modelowi przypisywać różne wagi sąsiadom, uwzględniając wagę ich istotności w kontekście rekomendacji.
Zalety sieci grafowych:
\begin{itemize}
	\item Efektywne wykorzystanie informacji dodatkowych: Sieci grafowe skutecznie integrują cechy przedmiotów, profile użytkowników i inne dane kontekstowe, co poprawia wyniki rekomendacji.
\item Modelowanie relacji wyższego rzędu: KGAT potrafi uchwycić dalekie powiązania między węzłami, co jest problematyczne dla tradycyjnych metod.
\item Interpretowalność: Mechanizm uwagi pozwala interpretować, które relacje miały największy wpływ na wyniki modelu.
\item Brak potrzeby ręcznego definiowania ścieżek: W przeciwieństwie do metod opartych na ścieżkach, KGAT nie wymaga ręcznego definiowania ścieżek, co oszczędza czas i zasoby.
\end{itemize}

Wady sieci grafowych:
\begin{itemize}
	\item Wysokie wymagania obliczeniowe: Liczba węzłów i relacji rośnie eksponencjalnie wraz ze wzrostem złożoności grafu, co może być problematyczne dla większych problemów.
	\item Złożoność modelowania relacji: Relacje wyższego rzędu wnoszą różny wkład do rekomendacji, co wymaga precyzyjnego ważenia i selekcji.
	\item Brak interpretowalności w niektórych modelach: Chociaż KGAT stawia na interpretowalność, inne podejścia (np. regularizacyjne) mogą być trudniejsze do zrozumienia.
\end{itemize}
\section{Opis architektury}
\subsection{Szczegółowy opis algorytmu}
	
Algorytm KGAT składa się z trzech głównych komponentów:
\begin{itemize}
	\item Warstwa osadzania: Parametryzuje każdy węzeł jako wektor, zachowując strukturę grafu wiedzy.
	\item Warstwy propagacji osadzania z uwzględnieniem uwagi: Rekurencyjnie propagują osadzenia od sąsiadów węzła, aktualizując jego reprezentację i ucząc się wagi każdego sąsiada podczas propagacji.
	\item Warstwa predykcji: Agreguje reprezentacje użytkownika i przedmiotu ze wszystkich warstw propagacji i zwraca przewidywany wynik dopasowania.
\end{itemize}
\subsection{Parametry Algorytmu}
Wśród parametrów modelu możemy wyróżnić hiperparametry, w tym przypadku wymiar warstwy osadzeń i liczba wartsw propagacji. Dodatkowo algorytm dynamicznie wybiera rozmiary
osadzeń w zależności od węzłów, co pozwala na bardziej elastyczne modelowanie relacji oraz wagi warstwy attention (warstwy uwagi. wagi uwagi brzmiały na tyle głupio że wolę używeać angielskiego).
\subsection{Format danych wejściowych}
Danymi wejściowymi grafu są trójki relacji między węzłami, w formacie (h, r, t), gdzie h to węzeł początkowy, r to relacja między węzłami, a t to węzeł docelowy.\\
Danymi wyjściowymi są przewidywane wyniki dopasowania użytkownika do przedmiotu.

\subsection{Warstwy osadzania i atencji}

\paragraph{Warstwa osadzania} Knowledge Graph Attention Network (KGAT) wykorzystuje warstwę embeddingu do reprezentowania encji i relacji w grafie wiedzy jako wektorów liczbowych. Model ten bazuje na metodzie osadzania grafów wiedzy TransR, która umożliwia modelowanie semantyki relacji między encjami.

\paragraph{Osadzanie encji i relacji} Każda encja \( h \), \( t \) i relacja \( r \) w grafie wiedzy jest reprezentowana jako wektor w przestrzeni wektorowej. Przekształcanie osadzeń odbywa się poprzez macierz transformacji \( W_r \), która rzutuje encje do przestrzeni specyficznej dla danej relacji:
\begin{equation}
    e_r(h) + e_r \approx e_r(t),
\end{equation}
co oznacza, że wektor encji początkowej powinien być bliski wektorowi encji docelowej po zastosowaniu transformacji relacyjnej.

\paragraph{Funkcja kosztu} W celu optymalizacji osadzeń KGAT minimalizuje funkcję kosztu, opartą na rangowej stracie logistycznej:
\begin{equation}
    L_{KG} = \sum_{(h,r,t,t')} - \ln \sigma \left( g(h, r, t') - g(h, r, t) \right),
\end{equation}
co pozwala na skuteczne rozróżnianie prawdziwych i fałszywych relacji w grafie.

\paragraph{Warstwy atencji i propagacji embeddingu} Aby efektywnie modelować zależności wysokiego rzędu w grafie wiedzy, KGAT stosuje propagację embeddingów inspirowaną sieciami grafowymi (Graph Neural Networks, GNN) oraz mechanizmem atencji (attention mechanism). 

\paragraph{Propagacja informacji} Dla każdej encji \( h \), nowa reprezentacja jest wyliczana na podstawie jej sąsiednich węzłów \( t \) oraz relacji \( r \). Wartość propagacji kontroluje współczynnik tłumienia \( \pi(h, r, t) \), który określa ilość informacji przekazywanej z węzła \( t \) do \( h \):
\begin{equation}
    e_{N_h} = \sum_{(h,r,t) \in N_h} \pi(h, r, t) e_t.
\end{equation}

\paragraph{Mechanizm atencji} Aby poprawić jakość rekomendacji, KGAT wykorzystuje mechanizm atencji do dynamicznego przypisywania różnych wag do sąsiednich węzłów w trakcie propagacji embeddingów. Waga relacji \( \pi(h, r, t) \) jest obliczana jako:
\begin{equation}
    \pi(h, r, t) = (W_r e_t)^\top \tanh(W_r e_h + e_r),
\end{equation}
po czym wartości te są normalizowane za pomocą funkcji softmax:
\begin{equation}
    \pi(h, r, t) = \frac{\exp(\pi(h, r, t))}{\sum_{(h,r',t') \in N_h} \exp(\pi(h, r', t'))}.
\end{equation}
Dzięki temu model może selektywnie wzmacniać istotne zależności między encjami.

\paragraph{Agregacja informacji} Ostateczna reprezentacja węzła \( h \) jest sumą jego oryginalnej reprezentacji oraz propagowanych embeddingów, co można zapisać jako:
\begin{equation}
    e_h^{(1)} = f(e_h, e_{N_h}).
\end{equation}
KGAT testuje różne strategie agregacji, w tym:
% \begin{itemize}
    % \item \textbf{Sumowanie (GCN Aggregator):} $f_{GCN} = \text{LeakyReLU}(W(e_h + e_{N_h}))$,
    % \item \textbf{Konkatenację (GraphSAGE Aggregator):} $f_{GraphSage} = \text{LeakyReLU}(W(e_h \| e_{N_h}))$,
    % \item \textbf{Interakcję dwukierunkową (Bi-Interaction Aggregator):} $f_{Bi-Interaction} = \text{LeakyReLU}(W_1(e_h + e_{N_h})) + \text{LeakyReLU}(W_2(e_h \odot e_{N_h}))$.
% \end{itemize}

\paragraph{Wielowarstwowa propagacja} Model KGAT może iteracyjnie propagować embeddingi przez wiele warstw, co pozwala uchwycić zależności wysokiego rzędu:
\begin{equation}
    e_h^{(l)} = f(e_h^{(l-1)}, e_{N_h}^{(l-1)}).
\end{equation}
Zastosowanie kilku warstw umożliwia modelowi uwzględnienie relacji o wyższych rzędach, co poprawia jakość rekomendacji.

\paragraph{Podsumowanie} Warstwy embeddingu i atencji w KGAT umożliwiają efektywne modelowanie wysokorzędowych zależności w grafie wiedzy. Mechanizm atencji pozwala na selektywne ważenie informacji od sąsiadujących węzłów, a propagacja embeddingów umożliwia hierarchiczne przekazywanie informacji. Dzięki temu KGAT osiąga lepsze wyniki w rekomendacjach niż wcześniejsze metody, jednocześnie oferując lepszą interpretowalność wyników.

\subsection{Uniwersalność}
Algorytm może być stosowany w różnych domenach, ale wymaga odpowiedniego grafu wiedzy który trzeba przygotować przed procesem uczenia. Dodatkowo jego 
złożoność obliczeniowa sprawia, że może być problematyczny bądź nawet niemożliwy dla większych zbiorów danych.
	
\section{Przegląd metod rekomendacyjnych}

Systemy rekomendacyjne stanowią kluczowy element nowoczesnych aplikacji internetowych, umożliwiając personalizację treści na podstawie analizy zachowań użytkowników. W niniejszej sekcji przedstawiono główne podejścia stosowane w systemach rekomendacyjnych wraz z ich zaletami i ograniczeniami.

\subsection{Filtracja kolaboratywna}
Filtracja kolaboratywna (ang. \textit{Collaborative Filtering, CF}) opiera się na analizie wzorców zachowań użytkowników w celu przewidywania ich preferencji. Wyróżnia się dwa główne podejścia:
\begin{itemize}
	\item \textit{User-based CF} – rekomendacje są generowane na podstawie podobieństwa między użytkownikami,
	\item \textit{Item-based CF} – rekomendacje bazują na podobieństwie między przedmiotami.
\end{itemize}
Zaletą metody jest jej niezależność od treści przedmiotów, jednak problemem pozostaje efekt zimnego startu oraz skomplikowana skalowalność w przypadku dużych zbiorów danych.

\subsection{Dekompozycja macierzy (Matrix Factorization)}
Dekompozycja macierzy (ang. \textit{Matrix Factorization, MF}), np. metoda SVD (ang. \textit{Singular Value Decomposition}) lub ALS (ang. \textit{Alternating Least Squares}), redukuje wymiarowość danych poprzez reprezentację interakcji użytkownik-przedmiot w przestrzeni ukrytych cech. Pozwala to na identyfikację wzorców preferencji, lecz metoda ta nadal cierpi na problem zimnego startu i słabo modeluje skomplikowane zależności.

\subsection{Filtracja oparta na treści}
Podejście oparte na treści (ang. \textit{Content-Based Filtering}) analizuje cechy przedmiotów (np. gatunek filmu, słowa kluczowe w artykule) w celu przewidywania preferencji użytkownika. Metoda ta dobrze sprawdza się w przypadku nowych użytkowników, jednak może prowadzić do efektu \textit{filter bubble}, czyli zbyt homogenicznych rekomendacji.

\subsection{Metody wykorzystujące głębokie sieci neuronowe}
Głębokie sieci neuronowe (ang. \textit{Deep Learning-based Recommendations}), np. \textit{Neural Collaborative Filtering (NCF)} lub autoenkodery, pozwalają na modelowanie nieliniowych zależności w danych. Chociaż zapewniają wysoką jakość rekomendacji, wymagają znacznych zasobów obliczeniowych oraz dużych zbiorów danych do skutecznego działania.

\subsection{Rekomendacje oparte na grafach}
Metody oparte na grafach (ang. \textit{Graph-Based Recommendations}), takie jak \textit{Graph Neural Networks (GNN)} czy \textit{Knowledge Graph Attention Network (KGAT)}, modelują relacje między użytkownikami i przedmiotami w postaci struktur grafowych. Takie podejście umożliwią lepsze uchwycenie kontekstowych zależności, lecz ich implementacja jest kosztowna obliczeniowo.

\subsection{Podejścia hybrydowe}
Hybrydowe systemy rekomendacyjne łączą powyższe podejścia w celu uzyskania bardziej precyzyjnych wyników. Przykładem jest system rekomendacyjny Netflixa, który integruje filtrację kolaboratywną, analizę treści oraz uczenie głębokie. Choć hybrydowe podejścia są bardzo skuteczne, ich implementacja jest złożona i wymaga znacznych zasobów obliczeniowych.

\subsection{Podsumowanie}
Tabela \ref{tab:comparison} przedstawia porównanie kluczowych metod rekomendacyjnych pod kątem zalet i ograniczeń.


\begin{table*}[t]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Metoda} & \textbf{Zalety} & \textbf{Ograniczenia} \\
        \hline
        Filtracja kolaboratywna & Wysoka skuteczność przy dużych danych & Problem zimnego startu, skalowalność \\
        \hline
        Matrix Factorization & Kompaktowa reprezentacja danych & Nie modeluje skomplikowanych zależności \\
        \hline
        Filtracja oparta na treści & Nie wymaga dużych zbiorów użytkowników & Filter bubble, wymaga cech przedmiotów \\
        \hline
        Deep Learning & Wysoka jakość rekomendacji & Wymaga dużych danych, koszt obliczeniowy \\
        \hline
        Graph-Based & Modeluje złożone relacje & Kosztowna implementacja \\
        \hline
        Podejścia hybrydowe & Najlepsza jakość rekomendacji & Złożona integracja, wysokie wymagania obliczeniowe \\
        \hline
    \end{tabular}
    \caption{Porównanie metod rekomendacyjnych}
    \label{tab:comparison}
\end{table*}

\section{Porównanie istniejących technologii}

	\section{Task 3}
	W trzecim etapie projektu studenci, korzystając z wiedzy zdobytej 
	w poprzednich dwóch etapach projektu, proponują własną modyfikację algorytmu 
	i/lub eksperymentu przeprowadzonego przez autorów oryginalnego artykułu i 
	planują eksperyment mający na celu weryfikację zaproponowanej modyfikacji.
	Na początku studenci powinni przemyśleć możliwe modyfikacje, które 
	zidentyfikowali w poprzednich sprawozdaniach. Można też rozszerzyć pulę 
	o nowe propozycje. Studenci powinni opisać wszystkie zidentyfikowane przez 
	siebie możliwe modyfikacje, zarówno samego algorytmu, jak i eksperymentu (nie 
	obliguje to do implementacji wszystkich rozszerzeń w kolejnym etapie).
	Podczas opisu każdej z możliwych modyfikacji algorytmu i/lub 
	eksperymentu, studenci powinni rozważyć następujące kwestie:
	\begin{itemize}
		\item Na czym polega dana modyfikacja?
		\item W jaki sposób zmieni ona sposób wykonania algorytmu/eksperymentu?
		\item W którym miejscu w kodzie będą wprowadzone zmiany?
		\item Jakie są motywacje wprowadzenia danej modyfikacji?
		\item Czy pozwoli ona ulepszyć algorytm/eksperyment? W jaki sposób?
		\item W przypadku modyfikacji eksperymentu powinno się rozważyć również pytania:
		\begin{itemize}
			\item Jaką nową wiedzę o metodzie możemy zyskać dzięki danej modyfikacji eksperymentu?
			\item Do czego w praktyce może się ta wiedza przydać?
		\end{itemize}
	\end{itemize}
	W ostatniej części etapu trzeciego studenci wybierają dwie modyfikacje i 
	planują dla nich eksperymenty. Należy również uzasadnić wybór modyfikacji do 
	implementacji.
	Plan eksperymentu powinien zawierać informacje o tym, co będzie badane 
	i w jaki sposób. Studenci powinni zidentyfikować wszystkie zmienne zależne i
	niezależne, w tym również hiperparametry wymagające wcześniejszego 
	strojenia. Każdy krok eksperymentu powinien być dokładnie zaplanowany i 
	opisany. Ważny jest również wybór i opis zbiorów danych do eksperymentu.

	\subsection{Prezentacja do Etapu III}
	Prezentacja z Etapu III powinna zawierać podstawowe informacje 
	o autorach, tj. imiona, nazwiska i numery indeksów wszystkich członków zespołu 
	projektowego oraz informacje o analizowanym artykule, tj. nazwiska autorów i 
	tytuł. 
	Poniżej podano wymagane elementy merytoryczne sprawozdania.
	Prezentacja powinna trwać 10-12 minut.
	\begin{enumerate}
		\item Możliwe modyfikacje
		\begin{itemize}
			\item Dla każdej zidentyfikowanej możliwej modyfikacji, studenci powinni rozważyć następujące elementy:
			\begin{enumerate}
				\item Istota modyfikacji
				\begin{itemize}
					\item Typ modyfikacji (algorytmu czy eksperymentu).
					\item Na czym polega dana modyfikacja?
					\item W jaki sposób zmieni ona sposób wykonania algorytmu/eksperymentu?
					\item W którym miejscu w kodzie będą wprowadzone zmiany?
				\end{itemize}
				\item Motywacje do wprowadzenia danej modyfikacji
				\begin{itemize}
					\item Jakie są motywacje wprowadzenia danej modyfikacji?
					\item Czy pozwoli ona ulepszyć algorytm/eksperyment? W jaki sposób?
					\item Opcjonalne (tylko w przypadku modyfikacji eksperymentu): Jaką nową wiedzę o metodzie możemy zyskać dzięki danej modyfikacji eksperymentu? Do czego w praktyce może się ta wiedza przydać?
				\end{itemize}
			\end{enumerate}
		\end{itemize}
		\item Plan eksperymentu
		\begin{enumerate}
			\item Wybór modyfikacji
			\begin{itemize}
				\item Która z powyższych modyfikacji została wybrana do implementacji? Dlaczego akurat ta?
			\end{itemize}
			\item Opis eksperymentu
			\begin{itemize}
				\item Dokładny opis planowanego eksperymentu.
				\item Jakie zbiory danych zostaną wykorzystane?
				\item Jakie kroki zostaną przeprowadzone?
				\item Co będziemy badać?
				\item Jakie będą zmienne zależne a jakie niezależne w projektowanym eksperymencie?
				\item Czy będą wykorzystywane miary jakości systemów rekomendacyjnych? Jeśli tak, to jakie?
				\item Czy wymagane jest wcześniejsze strojenie hiperparametrów modelu? Jeżeli tak, to których i w jaki sposób będzie wykonane?
			\end{itemize}
		\end{enumerate}
	\end{enumerate}

	\section{Task 4}
	W czwartym etapie projektu studenci, korzystając z planu eksperymentu
	zaprojektowanego w trzecim etapie, przeprowadzają eksperyment naukowy,
	analizują jego wyniki i formułują wnioski.
	W pierwszej części czwartego etapu studenci powinni wykonać dwa
	eksperymenty zgodnie z planem opisanym w sprawozdaniu do etapu trzeciego.
	Istotna jest tutaj zgodność z opisanym planem. Jeżeli wystąpią jakiekolwiek
	trudności z realizacją zaplanowanych w eksperymencie czynności, studenci
	powinni opisać te problemy wraz z rozwiązaniem, które zostało zastosowane.
	Wszelkie modyfikacje planu również powinny zostać skrupulatnie opisane.
	Po wykonaniu każdego z eksperymentów, studenci powinni zebrać
	otrzymane wyniki w wygodnej do analizy formie, np. wykres, tabela. Dobrze by
	było, gdyby zostały przedstawione w takiej formie, która umożliwia porównanie
	otrzymanych wyników z tymi z oryginalnego artykułu (w uzasadnionych
	przypadkach nie jest to konieczne). Otrzymane wyniki powinny zostać
	przeanalizowane samodzielnie, jak również porównane z tymi z oryginalnego
	artykułu (o ile to możliwe). Na podstawie planu modyfikacji i wyników oraz
	oryginalnego artykułu, studenci powinni wyciągnąć wnioski z przeprowadzonych
	badań (dla każdego eksperymentu osobno).
	W ostatniej części etapu czwartego studenci podsumowują pracę ze
	wszystkich dotychczasowych etapów i wyciągają wnioski końcowe. Kluczowe
	jest zidentyfikowanie, czy podczas przeprowadzonych eksperymentów powstała
	nowa wiedza o badanym algorytmie (i opisanie jej, jeśli tak). Możliwe jest tu
	uwzględnienie wszelkich uwag dotyczących oryginalnej metody, procedury
	ewaluacji, zaimplementowanych modyfikacjach i otrzymanych wyników.

	\subsection{Prezentacja do Etapu IV}
	Prezentacja z Etapu IV powinna zawierać podstawowe informacje
	o autorach, tj. imiona, nazwiska i numery indeksów wszystkich członków
	zespołu projektowego oraz informacje o analizowanym artykule, tj. nazwiska
	autorów i tytuł. 
	Poniżej podano ramowe elementy merytoryczne sprawozdania.
	\begin{enumerate}
		\item Analizowany algorytm
		\begin{itemize}
			\item Krótkie przypomnienie, co robi analizowany algorytm.
		\end{itemize}
		\item Eksperymenty
		\begin{enumerate}
			\item Przebieg eksperymentu
			\begin{itemize}
				\item Dokładny opis przeprowadzonego eksperymentu.
				\item Czy udało się przeprowadzić modyfikację zgodnie z założonym planem? Jeśli nie, to co się zmieniło?
				\item Czy wystąpiły jakieś niespodziewane problemy? Jeśli tak, to jakie?
			\end{itemize}
			\item Wyniki
			\begin{itemize}
				\item Dokładny opis otrzymanych wyników z eksperymentu wraz z tabelami i/lub wykresami.
			\end{itemize}
			\item Porównanie wyników i wnioski
			\begin{itemize}
				\item Czy wyniki różnią się od wyników otrzymanych przez autorów oryginalnego artykułu? Jeśli tak, to czy są lepsze czy gorsze? Jak myślisz, dlaczego tak jest?
				\item Jeśli modyfikacją było nowe zastosowanie metody, to czy po przeprowadzonym eksperymencie możemy uznać, że metoda sprawdzi się w tym zastosowaniu? Dlaczego? Itd.
			\end{itemize}
		\end{enumerate}
		\item Wnioski końcowe
		\begin{itemize}
			\item Co możesz powiedzieć o oryginalnym algorytmie i własnych modyfikacjach po przeprowadzeniu eksperymentów?
			\item Czy możesz wysnuć jakieś wnioski z wszystkich eksperymentów (z artykułu i własnych)?
			\item Czy powstała nowa wiedza podczas realizacji projektu? Jeśli tak, to jaka? Itp.
		\end{itemize}
	\end{enumerate}

	\section{Task 5}
	\subsection{Przebieg Etapu V}
	W piątym etapie projektu studenci przygotowują artykuł naukowy zgodnie
	z załączonym szablonem.
	Artykuł powinien zawierać wszystkie kluczowe informacje dotyczące
	wszystkich wcześniejszych etapów projektu, ze szczególnym naciskiem na etap
	czwarty (własny eksperyment i wnioski).

	\subsection{Sprawozdanie do Etapu V}
	Sprawozdanie z Etapu V będzie stanowił artykuł naukowy, który powinien
	zawierać podstawowe informacje o autorach, tj. imiona i nazwiska wszystkich
	członków zespołu projektowego oraz informacje o analizowanym artykule, tj.
	nazwiska autorów i tytuł. Ponadto, artykuł powinien zawierać następujące
	elementy:
	\begin{enumerate}
		\item Wprowadzenie do problematyki.
		\item Przegląd stanu wiedzy/istniejących modyfikacji algorytmu
		\item Analizowany algorytm
		\item Przeprowadzone eksperymenty wraz z wynikami
		\item Wnioski końcowe
	\end{enumerate}
	Dokładny dobór treści w ramach punktów jest pozostawiony studentom
	i podlega ocenie.
	Artykuł powinien być napisany w języku angielskim z wykorzystaniem
	załączonego szablonu LaTeX. Długość artykułu powinna wynosić 10-14 stron
	(łącznie z bibliografią).

	\subsection{Forma i sposób zaliczenia Etapu V}
	Za etap można otrzymać maksymalnie 8 punktów. Do zaliczenia zadania
	wymagane jest otrzymanie minimum 4 punkty. Oceniany będzie dobór i sposób
	zaprezentowania treści. Termin wgrania artykułów upływa 21.01.2024 o godz.
	23:59.

	%----------------------------------------------------------------------------------------
	%	 REFERENCES
	%----------------------------------------------------------------------------------------
	
	\printbibliography % Output the bibliography
	
	%----------------------------------------------------------------------------------------
	
\end{document}